{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\"\"\"\n",
    "训练常用视觉基础网络，用于分类任务\n",
    "需要将训练图片，类别文件 label_list.txt 放置在同一个文件夹下\n",
    "程序会先读取 train.txt 文件获取类别数和图片数量\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import codecs\n",
    "import logging\n",
    "\n",
    "from paddle.fluid.initializer import MSRA\n",
    "from paddle.fluid.initializer import Uniform\n",
    "from paddle.fluid.param_attr import ParamAttr\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parameters = {   \n",
    "    \"input_size\": [3, 224, 224],\n",
    "    \"class_dim\": -1,  # 分类数，会在初始化自定义 reader 的时候获得   \n",
    "    \"image_count\": -1,  # 训练图片数量，会在初始化自定义 reader 的时候获得   \n",
    "    \"label_dict\": {},  # 类别编号与类别名之间的映射关系\n",
    "    \"data_dir\": \"data/data2815\",  # 训练数据存储地址   \n",
    "    \"train_file_list\": \"train.txt\",   \n",
    "    \"label_file\": \"label_list.txt\",   \n",
    "    \"save_freeze_dir\": \"./freeze-model\",   \n",
    "    \"save_persistable_dir\": \"./persistable-params\",   \n",
    "    \"continue_train\": False,        # 是否接着上一次保存的参数接着训练，优先级高于预训练模型   \n",
    "    \"pretrained\": True,            # 是否使用预训练的模型   \n",
    "    \"pretrained_dir\": \"data/GoogleNet_pretrained\",    \n",
    "    \"mode\": \"train\",   \n",
    "    \"num_epochs\": 120,   \n",
    "    \"train_batch_size\": 30,   \n",
    "    \"mean_rgb\": [127.5, 127.5, 127.5],  # 常用图片的三通道均值，通常来说需要先对训练数据做统计，此处仅取中间值   \n",
    "    \"use_gpu\": True,   \n",
    "    \"dropout_seed\": None,   \n",
    "    \"image_enhance_strategy\": {  # 图像增强相关策略   \n",
    "        \"need_distort\": True,  # 是否启用图像颜色增强   \n",
    "        \"need_rotate\": True,   # 是否需要增加随机角度   \n",
    "        \"need_crop\": True,      # 是否要增加裁剪   \n",
    "        \"need_flip\": True,      # 是否要增加水平随机翻转   \n",
    "        \"hue_prob\": 0.5,   \n",
    "        \"hue_delta\": 18,   \n",
    "        \"contrast_prob\": 0.5,   \n",
    "        \"contrast_delta\": 0.5,   \n",
    "        \"saturation_prob\": 0.5,   \n",
    "        \"saturation_delta\": 0.5,   \n",
    "        \"brightness_prob\": 0.5,   \n",
    "        \"brightness_delta\": 0.125   \n",
    "    },   \n",
    "    \"early_stop\": {   \n",
    "        \"sample_frequency\": 50,   \n",
    "        \"successive_limit\": 3,   \n",
    "        \"good_acc1\": 0.92   \n",
    "    },   \n",
    "    \"rsm_strategy\": {   \n",
    "        \"learning_rate\": 0.001,   \n",
    "        \"lr_epochs\": [20, 40, 60, 80, 100],   \n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1, 0.01, 0.002]   \n",
    "    },   \n",
    "    \"momentum_strategy\": {   \n",
    "        \"learning_rate\": 0.001,   \n",
    "        \"lr_epochs\": [20, 40, 60, 80, 100],   \n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1, 0.01, 0.002]   \n",
    "    },   \n",
    "    \"sgd_strategy\": {   \n",
    "        \"learning_rate\": 0.001,   \n",
    "        \"lr_epochs\": [20, 40, 60, 80, 100],   \n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1, 0.01, 0.002]   \n",
    "    },   \n",
    "    \"adam_strategy\": {   \n",
    "        \"learning_rate\": 0.002   \n",
    "    }   \n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleNet():\n",
    "    \"\"\"\n",
    "    GoogleNet网络类\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.params = train_parameters\n",
    "\n",
    "    def conv_layer(self,\n",
    "                   input,\n",
    "                   num_filters,  # 卷积核数量\n",
    "                   filter_size,  # 卷积核尺寸\n",
    "                   stride=1,  # 步长\n",
    "                   groups=1,  \n",
    "                   act=None,\n",
    "                   name=None):\n",
    "        channels = input.shape[1]  # 通道数\n",
    "        # 卷积层权重初始化方式,随机均匀初始化\n",
    "        stdv = (3.0 / (filter_size**2 * channels))**0.5\n",
    "        param_attr = ParamAttr(\n",
    "            initializer=fluid.initializer.Uniform(-stdv, stdv),\n",
    "            name=name + \"_weights\")\n",
    "        conv = fluid.layers.conv2d(\n",
    "            input=input,\n",
    "            num_filters=num_filters,  # 卷积核数量\n",
    "            filter_size=filter_size,  # 卷积核尺寸\n",
    "            stride=stride,  # 步长\n",
    "            padding=(filter_size - 1) // 2,  # 填充大小\n",
    "            groups=groups,  # Conv2d转置层的groups个数\n",
    "            act=act,  # 激活函数类型\n",
    "            param_attr=param_attr,\n",
    "            bias_attr=False,  # bias\n",
    "            name=name)\n",
    "        return conv\n",
    "\n",
    "    # xavier 初始化\n",
    "    def xavier(self, channels, filter_size, name):\n",
    "        stdv = (3.0 / (filter_size**2 * channels))**0.5\n",
    "        param_attr = ParamAttr(\n",
    "            initializer=fluid.initializer.Uniform(-stdv, stdv),\n",
    "            name=name + \"_weights\")\n",
    "        return param_attr\n",
    "\n",
    "    # 定义 inception 结构\n",
    "    def inception(self,\n",
    "                  input,\n",
    "                  channels,\n",
    "                  filter1,  # 1维卷积核的数量\n",
    "                  filter3R,  # 3 * 3 卷积核前置 1 * 1 卷积核的数量\n",
    "                  filter3,  # 3 * 3 卷积核数量\n",
    "                  filter5R,  # 5 * 5 卷积核前置 1 * 1 卷积核的数量\n",
    "                  filter5,  # 5 * 5 卷积核数量\n",
    "                  proj,\n",
    "                  name=None):\n",
    "        # 1 * 1 conv\n",
    "        conv1 = self.conv_layer(\n",
    "            input=input,\n",
    "            num_filters=filter1,\n",
    "            filter_size=1,\n",
    "            stride=1,\n",
    "            act=None,\n",
    "            name=\"inception_\" + name + \"_1x1\")\n",
    "        # 1* 1 conv => 3 * 3 conv\n",
    "        conv3r = self.conv_layer(\n",
    "            input=input,\n",
    "            num_filters=filter3R,\n",
    "            filter_size=1,\n",
    "            stride=1,\n",
    "            act=None,\n",
    "            name=\"inception_\" + name + \"_3x3_reduce\")\n",
    "        conv3 = self.conv_layer(\n",
    "            input=conv3r,\n",
    "            num_filters=filter3,\n",
    "            filter_size=3,\n",
    "            stride=1,\n",
    "            act=None,\n",
    "            name=\"inception_\" + name + \"_3x3\")\n",
    "        # 1 * 1 conv => 5 * 5 conv\n",
    "        conv5r = self.conv_layer(\n",
    "            input=input,\n",
    "            num_filters=filter5R,\n",
    "            filter_size=1,\n",
    "            stride=1,\n",
    "            act=None,\n",
    "            name=\"inception_\" + name + \"_5x5_reduce\")\n",
    "        conv5 = self.conv_layer(\n",
    "            input=conv5r,\n",
    "            num_filters=filter5,\n",
    "            filter_size=5,\n",
    "            stride=1,\n",
    "            act=None,\n",
    "            name=\"inception_\" + name + \"_5x5\")\n",
    "        # 3 * 3 max pooling => 1 * 1 conv\n",
    "        pool = fluid.layers.pool2d(\n",
    "            input=input,\n",
    "            pool_size=3,\n",
    "            pool_stride=1,\n",
    "            pool_padding=1,\n",
    "            pool_type='max')\n",
    "        convprj = fluid.layers.conv2d(\n",
    "            input=pool,\n",
    "            filter_size=1,\n",
    "            num_filters=proj,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            name=\"inception_\" + name + \"_3x3_proj\",\n",
    "            param_attr=ParamAttr(\n",
    "                name=\"inception_\" + name + \"_3x3_proj_weights\"),\n",
    "            bias_attr=False)\n",
    "        cat = fluid.layers.concat(input=[conv1, conv3, conv5, convprj], axis=1)\n",
    "        cat = fluid.layers.relu(cat)\n",
    "        return cat\n",
    "    \n",
    "    # 定义网络结构\n",
    "    def net(self, input, class_dim=1000):\n",
    "        # 7 * 7 conv => 3 * 3 max pooling\n",
    "        conv = self.conv_layer(\n",
    "            input=input,\n",
    "            num_filters=64,\n",
    "            filter_size=7,\n",
    "            stride=2,\n",
    "            act=None,\n",
    "            name=\"conv1\")\n",
    "        pool = fluid.layers.pool2d(\n",
    "            input=conv, pool_size=3, pool_type='max', pool_stride=2)\n",
    "        # 1*1 conv => 3*3 conv\n",
    "        conv = self.conv_layer(\n",
    "            input=pool,\n",
    "            num_filters=64,\n",
    "            filter_size=1,\n",
    "            stride=1,\n",
    "            act=None,\n",
    "            name=\"conv2_1x1\")\n",
    "        conv = self.conv_layer(\n",
    "            input=conv,\n",
    "            num_filters=192,\n",
    "            filter_size=3,\n",
    "            stride=1,\n",
    "            act=None,\n",
    "            name=\"conv2_3x3\")\n",
    "        # 3*3 max pooling\n",
    "        pool = fluid.layers.pool2d(\n",
    "            input=conv, pool_size=3, pool_type='max', pool_stride=2)\n",
    "        # inception => incepiton => max pooling\n",
    "        ince3a = self.inception(pool, 192, 64, 96, 128, 16, 32, 32, \"ince3a\")\n",
    "        ince3b = self.inception(ince3a, 256, 128, 128, 192, 32, 96, 64,\n",
    "                                \"ince3b\")\n",
    "        pool3 = fluid.layers.pool2d(\n",
    "            input=ince3b, pool_size=3, pool_type='max', pool_stride=2)\n",
    "        # inception * 5 => max pooling\n",
    "        ince4a = self.inception(pool3, 480, 192, 96, 208, 16, 48, 64, \"ince4a\")\n",
    "        ince4b = self.inception(ince4a, 512, 160, 112, 224, 24, 64, 64,\n",
    "                                \"ince4b\")\n",
    "        ince4c = self.inception(ince4b, 512, 128, 128, 256, 24, 64, 64,\n",
    "                                \"ince4c\")\n",
    "        ince4d = self.inception(ince4c, 512, 112, 144, 288, 32, 64, 64,\n",
    "                                \"ince4d\")\n",
    "        ince4e = self.inception(ince4d, 528, 256, 160, 320, 32, 128, 128,\n",
    "                                \"ince4e\")\n",
    "        # inception => inception => avg pooling\n",
    "        pool4 = fluid.layers.pool2d(\n",
    "            input=ince4e, pool_size=3, pool_type='max', pool_stride=2)\n",
    "\n",
    "        ince5a = self.inception(pool4, 832, 256, 160, 320, 32, 128, 128,\n",
    "                                \"ince5a\")\n",
    "        ince5b = self.inception(ince5a, 832, 384, 192, 384, 48, 128, 128,\n",
    "                                \"ince5b\")\n",
    "        pool5 = fluid.layers.pool2d(\n",
    "            input=ince5b, pool_size=7, pool_type='avg', pool_stride=7)\n",
    "        # 最深层次的输出 dropout => fc(softmax)\n",
    "        dropout = fluid.layers.dropout(x=pool5, dropout_prob=0.4)\n",
    "        out = fluid.layers.fc(input=dropout,\n",
    "                              size=class_dim,\n",
    "                              act='softmax',\n",
    "                              param_attr=self.xavier(1024, 1, \"out\"),\n",
    "                              name=\"out\",\n",
    "                              bias_attr=ParamAttr(name=\"out_offset\"))\n",
    "        # 最浅层的输出\n",
    "        pool_o1 = fluid.layers.pool2d(\n",
    "            input=ince4a, pool_size=5, pool_type='avg', pool_stride=3)\n",
    "        conv_o1 = self.conv_layer(\n",
    "            input=pool_o1,\n",
    "            num_filters=128,\n",
    "            filter_size=1,\n",
    "            stride=1,\n",
    "            act=None,\n",
    "            name=\"conv_o1\")\n",
    "        fc_o1 = fluid.layers.fc(input=conv_o1,\n",
    "                                size=1024,\n",
    "                                act='relu',\n",
    "                                param_attr=self.xavier(2048, 1, \"fc_o1\"),\n",
    "                                name=\"fc_o1\",\n",
    "                                bias_attr=ParamAttr(name=\"fc_o1_offset\"))\n",
    "        dropout_o1 = fluid.layers.dropout(x=fc_o1, dropout_prob=0.7)\n",
    "        out1 = fluid.layers.fc(input=dropout_o1,\n",
    "                               size=class_dim,\n",
    "                               act='softmax',\n",
    "                               param_attr=self.xavier(1024, 1, \"out1\"),\n",
    "                               name=\"out1\",\n",
    "                               bias_attr=ParamAttr(name=\"out1_offset\"))\n",
    "        # 稍浅层的输出\n",
    "        pool_o2 = fluid.layers.pool2d(\n",
    "            input=ince4d, pool_size=5, pool_type='avg', pool_stride=3)\n",
    "        conv_o2 = self.conv_layer(\n",
    "            input=pool_o2,\n",
    "            num_filters=128,\n",
    "            filter_size=1,\n",
    "            stride=1,\n",
    "            act=None,\n",
    "            name=\"conv_o2\")\n",
    "        fc_o2 = fluid.layers.fc(input=conv_o2,\n",
    "                                size=1024,\n",
    "                                act='relu',\n",
    "                                param_attr=self.xavier(2048, 1, \"fc_o2\"),\n",
    "                                name=\"fc_o2\",\n",
    "                                bias_attr=ParamAttr(name=\"fc_o2_offset\"))\n",
    "        dropout_o2 = fluid.layers.dropout(x=fc_o2, dropout_prob=0.7)\n",
    "        out2 = fluid.layers.fc(input=dropout_o2,\n",
    "                               size=class_dim,\n",
    "                               act='softmax',\n",
    "                               param_attr=self.xavier(1024, 1, \"out2\"),\n",
    "                               name=\"out2\",\n",
    "                               bias_attr=ParamAttr(name=\"out2_offset\"))\n",
    "\n",
    "        # last fc layer is \"out\"\n",
    "        return out, out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-29 10:41:09,786-INFO: create prog success\n",
      "2019-12-29 10:41:09,786 - <ipython-input-4-b9f54c2e75f6>[line:305] - INFO: create prog success\n",
      "2019-12-29 10:41:09,788-INFO: train config: {'input_size': [3, 224, 224], 'class_dim': 5, 'image_count': 2929, 'label_dict': {'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}, 'data_dir': 'data/data2815', 'train_file_list': 'train.txt', 'label_file': 'label_list.txt', 'save_freeze_dir': './freeze-model', 'save_persistable_dir': './persistable-params', 'continue_train': False, 'pretrained': True, 'pretrained_dir': 'data/GoogleNet_pretrained', 'mode': 'train', 'num_epochs': 120, 'train_batch_size': 30, 'mean_rgb': [127.5, 127.5, 127.5], 'use_gpu': True, 'dropout_seed': None, 'image_enhance_strategy': {'need_distort': True, 'need_rotate': True, 'need_crop': True, 'need_flip': True, 'hue_prob': 0.5, 'hue_delta': 18, 'contrast_prob': 0.5, 'contrast_delta': 0.5, 'saturation_prob': 0.5, 'saturation_delta': 0.5, 'brightness_prob': 0.5, 'brightness_delta': 0.125}, 'early_stop': {'sample_frequency': 50, 'successive_limit': 3, 'good_acc1': 0.92}, 'rsm_strategy': {'learning_rate': 0.001, 'lr_epochs': [20, 40, 60, 80, 100], 'lr_decay': [1, 0.5, 0.25, 0.1, 0.01, 0.002]}, 'momentum_strategy': {'learning_rate': 0.001, 'lr_epochs': [20, 40, 60, 80, 100], 'lr_decay': [1, 0.5, 0.25, 0.1, 0.01, 0.002]}, 'sgd_strategy': {'learning_rate': 0.001, 'lr_epochs': [20, 40, 60, 80, 100], 'lr_decay': [1, 0.5, 0.25, 0.1, 0.01, 0.002]}, 'adam_strategy': {'learning_rate': 0.002}}\n",
      "2019-12-29 10:41:09,788 - <ipython-input-4-b9f54c2e75f6>[line:306] - INFO: train config: {'input_size': [3, 224, 224], 'class_dim': 5, 'image_count': 2929, 'label_dict': {'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}, 'data_dir': 'data/data2815', 'train_file_list': 'train.txt', 'label_file': 'label_list.txt', 'save_freeze_dir': './freeze-model', 'save_persistable_dir': './persistable-params', 'continue_train': False, 'pretrained': True, 'pretrained_dir': 'data/GoogleNet_pretrained', 'mode': 'train', 'num_epochs': 120, 'train_batch_size': 30, 'mean_rgb': [127.5, 127.5, 127.5], 'use_gpu': True, 'dropout_seed': None, 'image_enhance_strategy': {'need_distort': True, 'need_rotate': True, 'need_crop': True, 'need_flip': True, 'hue_prob': 0.5, 'hue_delta': 18, 'contrast_prob': 0.5, 'contrast_delta': 0.5, 'saturation_prob': 0.5, 'saturation_delta': 0.5, 'brightness_prob': 0.5, 'brightness_delta': 0.125}, 'early_stop': {'sample_frequency': 50, 'successive_limit': 3, 'good_acc1': 0.92}, 'rsm_strategy': {'learning_rate': 0.001, 'lr_epochs': [20, 40, 60, 80, 100], 'lr_decay': [1, 0.5, 0.25, 0.1, 0.01, 0.002]}, 'momentum_strategy': {'learning_rate': 0.001, 'lr_epochs': [20, 40, 60, 80, 100], 'lr_decay': [1, 0.5, 0.25, 0.1, 0.01, 0.002]}, 'sgd_strategy': {'learning_rate': 0.001, 'lr_epochs': [20, 40, 60, 80, 100], 'lr_decay': [1, 0.5, 0.25, 0.1, 0.01, 0.002]}, 'adam_strategy': {'learning_rate': 0.002}}\n",
      "2019-12-29 10:41:09,789-INFO: build input custom reader and data feeder\n",
      "2019-12-29 10:41:09,789 - <ipython-input-4-b9f54c2e75f6>[line:307] - INFO: build input custom reader and data feeder\n"
     ]
    }
   ],
   "source": [
    "def init_log_config():\n",
    "    \"\"\"\n",
    "    初始化日志相关配置\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global logger\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)  # 日志输出的最低等级 logging.INFO\n",
    "    log_path = os.path.join(os.getcwd(), 'logs')\n",
    "    if not os.path.exists(log_path):\n",
    "        os.makedirs(log_path)\n",
    "    log_name = os.path.join(log_path, 'train.log')\n",
    "    sh = logging.StreamHandler()\n",
    "    fh = logging.FileHandler(log_name, mode='w')\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s\")\n",
    "    fh.setFormatter(formatter)\n",
    "    sh.setFormatter(formatter)\n",
    "    logger.addHandler(sh)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "\n",
    "def init_train_parameters():\n",
    "    \"\"\"\n",
    "    初始化训练参数，主要是初始化图片数量，类别数\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train_file_list = os.path.join(train_parameters['data_dir'], train_parameters['train_file_list'])\n",
    "    label_list = os.path.join(train_parameters['data_dir'], train_parameters['label_file'])\n",
    "    index = 0\n",
    "    with codecs.open(label_list, encoding='utf-8') as flist:\n",
    "        lines = [line.strip() for line in flist]\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            # 初始化 label_dict\n",
    "            train_parameters['label_dict'][parts[1]] = int(parts[0])\n",
    "            index += 1\n",
    "        # 初始化 class_dim\n",
    "        train_parameters['class_dim'] = index\n",
    "    # 初始化 image_count\n",
    "    with codecs.open(train_file_list, encoding='utf-8') as flist:\n",
    "        lines = [line.strip() for line in flist]\n",
    "        train_parameters['image_count'] = len(lines)\n",
    "\n",
    "\n",
    "def resize_img(img, target_size):\n",
    "    \"\"\"\n",
    "    强制缩放图片\n",
    "    :param img:\n",
    "    :param target_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    target_size = input_size\n",
    "    img = img.resize((target_size[1], target_size[2]), Image.BILINEAR)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_crop(img, scale=[0.08, 1.0], ratio=[3. / 4., 4. / 3.]):\n",
    "    \"\"\"\n",
    "    图片随机裁剪，扣取中心区域\n",
    "    \"\"\"\n",
    "    aspect_ratio = math.sqrt(np.random.uniform(*ratio))\n",
    "    w = 1. * aspect_ratio\n",
    "    h = 1. / aspect_ratio\n",
    "\n",
    "    bound = min((float(img.size[0]) / img.size[1]) / (w**2),\n",
    "                (float(img.size[1]) / img.size[0]) / (h**2))\n",
    "    scale_max = min(scale[1], bound)\n",
    "    scale_min = min(scale[0], bound)\n",
    "\n",
    "    target_area = img.size[0] * img.size[1] * np.random.uniform(scale_min,\n",
    "                                                                scale_max)\n",
    "    target_size = math.sqrt(target_area)\n",
    "    w = int(target_size * w)\n",
    "    h = int(target_size * h)\n",
    "\n",
    "    i = np.random.randint(0, img.size[0] - w + 1)\n",
    "    j = np.random.randint(0, img.size[1] - h + 1)\n",
    "\n",
    "    img = img.crop((i, j, i + w, j + h))\n",
    "    img = img.resize((train_parameters['input_size'][1], train_parameters['input_size'][2]), Image.BILINEAR)\n",
    "    return img\n",
    "\n",
    "\n",
    "def rotate_image(img):\n",
    "    \"\"\"\n",
    "    图像增强，增加随机旋转角度\n",
    "    \"\"\"\n",
    "    angle = np.random.randint(-14, 15)\n",
    "    img = img.rotate(angle)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_brightness(img):\n",
    "    \"\"\"\n",
    "    图像增强，亮度调整\n",
    "    :param img:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < train_parameters['image_enhance_strategy']['brightness_prob']:\n",
    "        brightness_delta = train_parameters['image_enhance_strategy']['brightness_delta']\n",
    "        delta = np.random.uniform(-brightness_delta, brightness_delta) + 1\n",
    "        img = ImageEnhance.Brightness(img).enhance(delta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_contrast(img):\n",
    "    \"\"\"\n",
    "    图像增强，对比度调整\n",
    "    :param img:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < train_parameters['image_enhance_strategy']['contrast_prob']:\n",
    "        contrast_delta = train_parameters['image_enhance_strategy']['contrast_delta']\n",
    "        delta = np.random.uniform(-contrast_delta, contrast_delta) + 1\n",
    "        img = ImageEnhance.Contrast(img).enhance(delta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_saturation(img):\n",
    "    \"\"\"\n",
    "    图像增强，饱和度调整\n",
    "    :param img:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < train_parameters['image_enhance_strategy']['saturation_prob']:\n",
    "        saturation_delta = train_parameters['image_enhance_strategy']['saturation_delta']\n",
    "        delta = np.random.uniform(-saturation_delta, saturation_delta) + 1\n",
    "        img = ImageEnhance.Color(img).enhance(delta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_hue(img):\n",
    "    \"\"\"\n",
    "    图像增强，色度调整\n",
    "    :param img:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < train_parameters['image_enhance_strategy']['hue_prob']:\n",
    "        hue_delta = train_parameters['image_enhance_strategy']['hue_delta']\n",
    "        delta = np.random.uniform(-hue_delta, hue_delta)\n",
    "        img_hsv = np.array(img.convert('HSV'))\n",
    "        img_hsv[:, :, 0] = img_hsv[:, :, 0] + delta\n",
    "        img = Image.fromarray(img_hsv, mode='HSV').convert('RGB')\n",
    "    return img\n",
    "\n",
    "\n",
    "def distort_color(img):\n",
    "    \"\"\"\n",
    "    概率的图像增强\n",
    "    :param img:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    # Apply different distort order\n",
    "    if prob < 0.35:\n",
    "        img = random_brightness(img)  # 亮度\n",
    "        img = random_contrast(img)  # 对比度\n",
    "        img = random_saturation(img)  # 饱和度\n",
    "        img = random_hue(img)  # 色度\n",
    "    elif prob < 0.7:\n",
    "        img = random_brightness(img)  # 亮度\n",
    "        img = random_saturation(img)  # 饱和度\n",
    "        img = random_hue(img)  # 色度\n",
    "        img = random_contrast(img)  # 对比度\n",
    "    return img\n",
    "\n",
    "\n",
    "def custom_image_reader(file_list, data_dir, mode):\n",
    "    \"\"\"\n",
    "    自定义用户图片读取器，先初始化图片种类，数量\n",
    "    :param file_list:\n",
    "    :param data_dir:\n",
    "    :param mode:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    with codecs.open(file_list) as flist:\n",
    "        lines = [line.strip() for line in flist]\n",
    "\n",
    "    def reader():\n",
    "        np.random.shuffle(lines)  # shuffle\n",
    "        for line in lines:\n",
    "            if mode == 'train' or mode == 'val':\n",
    "                img_path, label = line.split()\n",
    "                img = Image.open(img_path)\n",
    "                try:\n",
    "                    if img.mode != 'RGB':\n",
    "                        img = img.convert('RGB')\n",
    "                    if train_parameters['image_enhance_strategy']['need_distort'] == True:\n",
    "                        img = distort_color(img)\n",
    "                    if train_parameters['image_enhance_strategy']['need_rotate'] == True:\n",
    "                        img = rotate_image(img)\n",
    "                    if train_parameters['image_enhance_strategy']['need_crop'] == True:\n",
    "                        img = random_crop(img, train_parameters['input_size'])\n",
    "                    if train_parameters['image_enhance_strategy']['need_flip'] == True:\n",
    "                        mirror = int(np.random.uniform(0, 2))\n",
    "                        if mirror == 1:\n",
    "                            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                    # HWC--->CHW && normalized\n",
    "                    img = np.array(img).astype('float32')\n",
    "                    img -= train_parameters['mean_rgb']\n",
    "                    img = img.transpose((2, 0, 1))  # HWC to CHW\n",
    "                    img *= 0.007843                 # 像素值归一化\n",
    "                    yield img, int(label)\n",
    "                except Exception as e:\n",
    "                    pass                            # 以防某些图片读取处理出错，加异常处理\n",
    "            elif mode == 'test':\n",
    "                img_path = os.path.join(data_dir, line)\n",
    "                img = Image.open(img_path)\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                img = resize_img(img, train_parameters['input_size'])\n",
    "                # HWC--->CHW && normalized\n",
    "                img = np.array(img).astype('float32')\n",
    "                img -= train_parameters['mean_rgb']\n",
    "                img = img.transpose((2, 0, 1))  # HWC to CHW\n",
    "                img *= 0.007843  # 像素值归一化\n",
    "                yield img\n",
    "\n",
    "    return reader\n",
    "\n",
    "\n",
    "def optimizer_momentum_setting():\n",
    "    \"\"\"\n",
    "    阶梯型的学习率适合比较大规模的训练数据\n",
    "    \"\"\"\n",
    "    learning_strategy = train_parameters['momentum_strategy']\n",
    "    batch_size = train_parameters[\"train_batch_size\"]\n",
    "    iters = train_parameters[\"image_count\"] // batch_size\n",
    "    lr = learning_strategy['learning_rate']\n",
    "\n",
    "    boundaries = [i * iters for i in learning_strategy[\"lr_epochs\"]]\n",
    "    values = [i * lr for i in learning_strategy[\"lr_decay\"]]\n",
    "    learning_rate = fluid.layers.piecewise_decay(boundaries, values)\n",
    "    optimizer = fluid.optimizer.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def optimizer_rms_setting():\n",
    "    \"\"\"\n",
    "    阶梯型的学习率适合比较大规模的训练数据\n",
    "    \"\"\"\n",
    "    batch_size = train_parameters[\"train_batch_size\"]\n",
    "    iters = train_parameters[\"image_count\"] // batch_size\n",
    "    learning_strategy = train_parameters['rsm_strategy']\n",
    "    lr = learning_strategy['learning_rate']\n",
    "\n",
    "    boundaries = [i * iters for i in learning_strategy[\"lr_epochs\"]]\n",
    "    values = [i * lr for i in learning_strategy[\"lr_decay\"]]\n",
    "\n",
    "    optimizer = fluid.optimizer.RMSProp(\n",
    "        learning_rate=fluid.layers.piecewise_decay(boundaries, values))\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def optimizer_sgd_setting():\n",
    "    \"\"\"\n",
    "    loss下降相对较慢，但是最终效果不错，阶梯型的学习率适合比较大规模的训练数据\n",
    "    \"\"\"\n",
    "    learning_strategy = train_parameters['sgd_strategy']\n",
    "    batch_size = train_parameters[\"train_batch_size\"]\n",
    "    iters = train_parameters[\"image_count\"] // batch_size\n",
    "    lr = learning_strategy['learning_rate']\n",
    "\n",
    "    boundaries = [i * iters for i in learning_strategy[\"lr_epochs\"]]\n",
    "    values = [i * lr for i in learning_strategy[\"lr_decay\"]]\n",
    "    learning_rate = fluid.layers.piecewise_decay(boundaries, values)\n",
    "    optimizer = fluid.optimizer.SGD(learning_rate=learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def optimizer_adam_setting():\n",
    "    \"\"\"\n",
    "    能够比较快速的降低 loss，但是相对后期乏力\n",
    "    \"\"\"\n",
    "    learning_strategy = train_parameters['adam_strategy']\n",
    "    learning_rate = learning_strategy['learning_rate']\n",
    "    optimizer = fluid.optimizer.Adam(learning_rate=learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def load_params(exe, program):\n",
    "    if train_parameters['continue_train'] and os.path.exists(train_parameters['save_persistable_dir']):\n",
    "        logger.info('load params from retrain model')\n",
    "        fluid.io.load_persistables(executor=exe,\n",
    "                                   dirname=train_parameters['save_persistable_dir'],\n",
    "                                   main_program=program)\n",
    "    elif train_parameters['pretrained'] and os.path.exists(train_parameters['pretrained_dir']):\n",
    "        logger.info('load params from pretrained model')\n",
    "        def if_exist(var):\n",
    "            return os.path.exists(os.path.join(train_parameters['pretrained_dir'], var.name))\n",
    "\n",
    "        fluid.io.load_vars(exe, train_parameters['pretrained_dir'], main_program=program,\n",
    "                           predicate=if_exist)\n",
    "\n",
    "\n",
    "def train():\n",
    "    train_prog = fluid.Program()\n",
    "    train_startup = fluid.Program()\n",
    "    logger.info(\"create prog success\")\n",
    "    logger.info(\"train config: %s\", str(train_parameters))\n",
    "    logger.info(\"build input custom reader and data feeder\")\n",
    "    file_list = os.path.join(train_parameters['data_dir'], \"train.txt\")\n",
    "    mode = train_parameters['mode']\n",
    "    batch_reader = paddle.batch(custom_image_reader(file_list, train_parameters['data_dir'], mode),\n",
    "                                batch_size=train_parameters['train_batch_size'],\n",
    "                                drop_last=False)\n",
    "    batch_reader = paddle.reader.shuffle(batch_reader, train_parameters['train_batch_size'])\n",
    "    place = fluid.CUDAPlace(0) if train_parameters['use_gpu'] else fluid.CPUPlace()\n",
    "    # 定义输入数据的占位符\n",
    "    img = fluid.layers.data(name='img', shape=train_parameters['input_size'], dtype='float32')\n",
    "    label = fluid.layers.data(name='label', shape=[1], dtype='int64')\n",
    "    feeder = fluid.DataFeeder(feed_list=[img, label], place=place)\n",
    "\n",
    "    # 选取不同的网络\n",
    "    logger.info(\"build newwork\")\n",
    "    model = GoogleNet()\n",
    "    out, out1, out2 = model.net(input=img, class_dim=train_parameters['class_dim'])\n",
    "    cost0 = fluid.layers.cross_entropy(input=out, label=label)\n",
    "    cost1 = fluid.layers.cross_entropy(input=out1, label=label)\n",
    "    cost2 = fluid.layers.cross_entropy(input=out2, label=label)\n",
    "    avg_cost0 = fluid.layers.mean(x=cost0)\n",
    "    avg_cost1 = fluid.layers.mean(x=cost1)\n",
    "    avg_cost2 = fluid.layers.mean(x=cost2)\n",
    "\n",
    "    avg_cost = avg_cost0 + 0.3 * avg_cost1 + 0.3 * avg_cost2\n",
    "    acc_top1 = fluid.layers.accuracy(input=out, label=label, k=1)\n",
    "    # 选取不同的优化器\n",
    "    optimizer = optimizer_rms_setting()\n",
    "    # optimizer = optimizer_momentum_setting()\n",
    "    # optimizer = optimizer_sgd_setting()\n",
    "    # optimizer = optimizer_adam_setting()\n",
    "    optimizer.minimize(avg_cost)\n",
    "    exe = fluid.Executor(place)\n",
    "\n",
    "    main_program = fluid.default_main_program()\n",
    "    exe.run(fluid.default_startup_program())\n",
    "    train_fetch_list = [avg_cost.name, acc_top1.name, out.name]\n",
    "    \n",
    "    load_params(exe, main_program)\n",
    "\n",
    "    # 训练循环主体\n",
    "    stop_strategy = train_parameters['early_stop']\n",
    "    successive_limit = stop_strategy['successive_limit']\n",
    "    sample_freq = stop_strategy['sample_frequency']\n",
    "    good_acc1 = stop_strategy['good_acc1']\n",
    "    successive_count = 0\n",
    "    stop_train = False\n",
    "    total_batch_count = 0\n",
    "    for pass_id in range(train_parameters[\"num_epochs\"]):\n",
    "        logger.info(\"current pass: %d, start read image\", pass_id)\n",
    "        batch_id = 0\n",
    "        for step_id, data in enumerate(batch_reader()):\n",
    "            t1 = time.time()\n",
    "            loss, acc1, pred_ot = exe.run(main_program,\n",
    "                                          feed=feeder.feed(data),\n",
    "                                          fetch_list=train_fetch_list)\n",
    "            t2 = time.time()\n",
    "            batch_id += 1\n",
    "            total_batch_count += 1\n",
    "            period = t2 - t1\n",
    "            loss = np.mean(np.array(loss))\n",
    "            acc1 = np.mean(np.array(acc1))\n",
    "            if batch_id % 10 == 0:\n",
    "                logger.info(\"Pass {0}, trainbatch {1}, loss {2}, acc1 {3}, time {4}\".format(pass_id, batch_id, loss, acc1,\n",
    "                                                                                            \"%2.2f sec\" % period))\n",
    "            # 简单的提前停止策略，认为连续达到某个准确率就可以停止了\n",
    "            if acc1 >= good_acc1:\n",
    "                successive_count += 1\n",
    "                logger.info(\"current acc1 {0} meets good {1}, successive count {2}\".format(acc1, good_acc1, successive_count))\n",
    "                fluid.io.save_inference_model(dirname=train_parameters['save_freeze_dir'],\n",
    "                                              feeded_var_names=['img'],\n",
    "                                              target_vars=[out],\n",
    "                                              main_program=main_program,\n",
    "                                              executor=exe)\n",
    "                if successive_count >= successive_limit:\n",
    "                    logger.info(\"end training\")\n",
    "                    stop_train = True\n",
    "                    break\n",
    "            else:\n",
    "                successive_count = 0\n",
    "\n",
    "            # 通用的保存策略，减小意外停止的损失\n",
    "            if total_batch_count % sample_freq == 0:\n",
    "                logger.info(\"temp save {0} batch train result, current acc1 {1}\".format(total_batch_count, acc1))\n",
    "                fluid.io.save_persistables(dirname=train_parameters['save_persistable_dir'],\n",
    "                                           main_program=main_program,\n",
    "                                           executor=exe)\n",
    "        if stop_train:\n",
    "            break\n",
    "    logger.info(\"training till last epcho, end training\")\n",
    "    fluid.io.save_persistables(dirname=train_parameters['save_persistable_dir'],\n",
    "                                           main_program=main_program,\n",
    "                                           executor=exe)\n",
    "    fluid.io.save_inference_model(dirname=train_parameters['save_freeze_dir'],\n",
    "                                              feeded_var_names=['img'],\n",
    "                                              target_vars=[out],\n",
    "                                              main_program=main_program.clone(for_test=True),\n",
    "                                              executor=exe)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    init_log_config()\n",
    "    init_train_parameters()\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
