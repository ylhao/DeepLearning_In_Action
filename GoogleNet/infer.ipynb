{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import    \n",
    "from __future__ import division    \n",
    "from __future__ import print_function    \n",
    "    \n",
    "import os    \n",
    "import numpy as np    \n",
    "import random    \n",
    "import time    \n",
    "import codecs    \n",
    "import sys    \n",
    "import functools    \n",
    "import math    \n",
    "import paddle    \n",
    "import paddle.fluid as fluid    \n",
    "from paddle.fluid import core    \n",
    "from paddle.fluid.param_attr import ParamAttr    \n",
    "from PIL import Image, ImageEnhance    \n",
    "    \n",
    "target_size = [3, 224, 224]    \n",
    "mean_rgb = [127.5, 127.5, 127.5]    \n",
    "data_dir = \"data/data2815\"    \n",
    "eval_file = \"eval.txt\"    \n",
    "use_gpu = True    \n",
    "place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()    \n",
    "exe = fluid.Executor(place)    \n",
    "save_freeze_dir = \"./freeze-model\"    \n",
    "[inference_program, feed_target_names, fetch_targets] = fluid.io.load_inference_model(dirname=save_freeze_dir, executor=exe)    \n",
    "# print(fetch_targets)    \n",
    "    \n",
    "    \n",
    "def crop_image(img, target_size):    \n",
    "    width, height = img.size    \n",
    "    w_start = (width - target_size[2]) / 2    \n",
    "    h_start = (height - target_size[1]) / 2    \n",
    "    w_end = w_start + target_size[2]    \n",
    "    h_end = h_start + target_size[1]    \n",
    "    img = img.crop((w_start, h_start, w_end, h_end))    \n",
    "    return img    \n",
    "    \n",
    "    \n",
    "def resize_img(img, target_size):    \n",
    "    ret = img.resize((target_size[1], target_size[2]), Image.BILINEAR)    \n",
    "    return ret    \n",
    "    \n",
    "    \n",
    "def read_image(img_path):    \n",
    "    img = Image.open(img_path)    \n",
    "    if img.mode != 'RGB':    \n",
    "        img = img.convert('RGB')    \n",
    "    img = crop_image(img, target_size)    \n",
    "    img = np.array(img).astype('float32')    \n",
    "    img -= mean_rgb    \n",
    "    img = img.transpose((2, 0, 1))  # HWC to CHW    \n",
    "    img *= 0.007843    \n",
    "    img = img[np.newaxis,:]    \n",
    "    return img    \n",
    "    \n",
    "    \n",
    "def infer(image_path):    \n",
    "    tensor_img = read_image(image_path)    \n",
    "    label = exe.run(inference_program, feed={feed_target_names[0]: tensor_img}, fetch_list=fetch_targets)    \n",
    "    return np.argmax(label)    \n",
    "    \n",
    "    \n",
    "def eval_all():    \n",
    "    eval_file_path = os.path.join(data_dir, eval_file)    \n",
    "    total_count = 0    \n",
    "    right_count = 0    \n",
    "    with codecs.open(eval_file_path, \"r\", encoding='utf-8') as flist:     \n",
    "        lines = [line.strip() for line in flist]    \n",
    "        t1 = time.time()    \n",
    "        for line in lines:    \n",
    "            total_count += 1    \n",
    "            parts = line.strip().split()    \n",
    "            result = infer(parts[0])    \n",
    "            print(\"infer result:{0} answer:{1}\".format(result, parts[1]))    \n",
    "            if str(result) == parts[1]:    \n",
    "                right_count += 1    \n",
    "        period = time.time() - t1    \n",
    "        print(\"total eval count:{0} cost time:{1} predict accuracy:{2}\".format(total_count, \"%2.2f sec\" % period, right_count / total_count))    \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':    \n",
    "    eval_all()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
